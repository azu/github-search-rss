{
    "version": "https://jsonfeed.org/version/1",
    "title": "repo:antifraudcg/proposals Issues",
    "home_page_url": "https://azu.github.io/github-search-rss/antifraudcg-proposals.json",
    "feed_url": "https://azu.github.io/github-search-rss/antifraudcg-proposals.json",
    "description": "repo:antifraudcg/proposals Issues on GitHub",
    "items": [
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/22659592?u=887c85e26cbbd56a20304dd6a593ec7d23b59395&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">This proposal is making Scrappy(SeCure Rate Assuring Protocol with PrivacY),<br>\na new scheme with strong privacy for Privacy State Token..</p>\n<p dir=\"auto\">Scrappy is a rate-limiter the same as Privacy Pass, but this restants to the timing correlation attack.<br>\nAlso, Scrappy works as E2E (between users and web service) in the hot paths (i.e., sign and verify),<br>\nso that the issuer does not need to receive high access from users.</p>\n<p dir=\"auto\"><strong>Slides:</strong> <a href=\"https://speakerdeck.com/akakou/scrappy-and-view-of-applying-to-web\" rel=\"nofollow\">https://speakerdeck.com/akakou/scrappy-and-view-of-applying-to-web</a><br>\n<strong>Base paper:</strong> <a href=\"https://www.ndss-symposium.org/ndss-paper/scrappy-secure-rate-assuring-protocol-with-privacy/\" rel=\"nofollow\">https://www.ndss-symposium.org/ndss-paper/scrappy-secure-rate-assuring-protocol-with-privacy/</a></p>\n<h3 dir=\"auto\">Note</h3>\n<ul dir=\"auto\">\n<li>Although Scrappy mainly assumes the user has a unique resource in the hardware device (in particular, the TPM),<br>\nwe can use other unique resources, the same as the Trust Token API.</li>\n<li>TODO</li>\n</ul>\n<h3 dir=\"auto\">Other Reference</h3>\n<p dir=\"auto\">Privacy State Token:<br>\n<a href=\"https://developers.google.com/privacy-sandbox/protections/private-state-tokens?hl=en\" rel=\"nofollow\">https://developers.google.com/privacy-sandbox/protections/private-state-tokens?hl=en</a></p>",
            "url": "https://github.com/antifraudcg/proposals/issues/21",
            "title": "New scheme for Privacy State Token: Scrappy",
            "date_modified": "2024-06-06T08:52:23.000Z",
            "date_published": "2024-03-02T01:19:16.000Z",
            "author": {
                "name": "akakou",
                "url": "https://github.com/akakou"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/22659592?u=887c85e26cbbd56a20304dd6a593ec7d23b59395&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">This proposal achieves privacy-friendly revocation (i.e., ban). In particular, it makes a web servicer(i.e., web server) capable of blocking users who have previously abused them; however, it has no risk for privacy violations.</p>\n<h3 dir=\"auto\">Background</h3>\n<p dir=\"auto\">As is well known, malicious actions (e.g., cheating in games) are a significant problem, including in Web applications.<br>\nTo solve these problems, revoking malicious users is an excellent function to reduce fraud.</p>\n<p dir=\"auto\">Currently, the most straightforward way of revocation is to use the user identifier strongly coupled with the user's identity.<br>\n(e.g., National ID, Phone number, IP address(?))</p>\n<p dir=\"auto\">However, they have privacy concerns, especially user tracking by services.</p>\n<h3 dir=\"auto\">Idea</h3>\n<p dir=\"auto\">This idea is for Web APIs to provide a privacy-enhanced revocation method.</p>\n<p dir=\"auto\">It mainly consists of a cryptographic anonymous blocklisting protocol such as EPID(Enhanced Privacy ID).  EPID is a signature scheme that ensures user anonymity but revocability, too. Using EPID, services can revoke users while not being able to track users. Specifically, EPID has the signature-based revocation ability that allows services to revoke users using their signature (without using the user's information).</p>\n<p dir=\"auto\">This API provides signing and part of joining(i.e., Key generation and Credential saving) in EPID and some security/privacy measures.</p>\n<p dir=\"auto\">Note that although EPID assumes a third-party entity (GM: Group Manager) limits the number of user's secret keys, the implementation to limit it is out of scope in this API. In other words, the proposal entrusts a defining identification method to the GM (like Secure Payment Confirmation API). In many cases, GM limits them on GM's website using IP addresses, SMS authentication, or other schemes.</p>\n<p dir=\"auto\">Moreover, the browser and extension developers can be and add the GM in other ways.</p>\n<h3 dir=\"auto\">Base ideas</h3>\n<p dir=\"auto\">Privacy-Enhanced Revocation(AFCG meetings)</p>\n<ul dir=\"auto\">\n<li><a href=\"https://github.com/antifraudcg/meetings/blob/main/2023/08-18.md\">https://github.com/antifraudcg/meetings/blob/main/2023/08-18.md</a></li>\n</ul>\n<p dir=\"auto\">Web hardware revocation API</p>\n<ul dir=\"auto\">\n<li><a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1599684268\" data-permission-text=\"Title is private\" data-url=\"https://github.com/antifraudcg/proposals/issues/19\" data-hovercard-type=\"issue\" data-hovercard-url=\"/antifraudcg/proposals/issues/19/hovercard\" href=\"https://github.com/antifraudcg/proposals/issues/19\">#19</a></li>\n</ul>\n<h3 dir=\"auto\">References</h3>\n<p dir=\"auto\">EPID: Enhanced Privacy ID</p>\n<ul dir=\"auto\">\n<li><a href=\"https://www.intel.com/content/www/us/en/developer/articles/technical/intel-enhanced-privacy-id-epid-security-technology.html\" rel=\"nofollow\">https://www.intel.com/content/www/us/en/developer/articles/technical/intel-enhanced-privacy-id-epid-security-technology.html</a></li>\n</ul>\n<p dir=\"auto\">Secure Payment Confirmation API</p>\n<ul dir=\"auto\">\n<li><a href=\"https://www.w3.org/TR/secure-payment-confirmation/\" rel=\"nofollow\">https://www.w3.org/TR/secure-payment-confirmation/</a></li>\n</ul>",
            "url": "https://github.com/antifraudcg/proposals/issues/20",
            "title": "(Privacy-Enhanced) Web Revocation API",
            "date_modified": "2024-03-20T19:42:02.000Z",
            "date_published": "2023-10-11T19:35:45.000Z",
            "author": {
                "name": "akakou",
                "url": "https://github.com/akakou"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/22659592?u=887c85e26cbbd56a20304dd6a593ec7d23b59395&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">This proposal achieves privacy-friendly web hardware revocation (i.e., hardware ban). In particular, it makes a web servicer(i.e., web server) capable of blocking users who have previously abused them without users' privacy violations.</p>\n<h3 dir=\"auto\">Background</h3>\n<p dir=\"auto\">As is well known, malicious actions on the internet are increasing, and it is a big problem. One of the factors that their prevention makes difficult is the user's anonymity. So servicer can't block users who have abused in the past because the servicer can't track the user.</p>\n<p dir=\"auto\">The easiest way to solve this problem is to track the user. It means servicers require strong identification schemes of users like SMS or credit card authentication (i.e., 3D secure). However, it causes privacy concerns.</p>\n<p dir=\"auto\">Thus, we need a method that blocks users who abuse in the past without tracking. In the mobile context, the DeivceCheck API of iOS satisfies them; they provide a hardware revocation scheme conscious of users' privacy. However, I can't find Web APIs like them. In addition, DeivceCheck API assumes common trusted execution comportment of devices, so many devices can't support it.</p>\n<h3 dir=\"auto\">Idea</h3>\n<p dir=\"auto\">This idea is for Web APIs to provide a hardware revocation method without violating user privacy.</p>\n<p dir=\"auto\">Mainly this idea consists of a cryptographic protocol and hardware registration protocol. The cryptographic protocol achieves revocation without tracking risk, but it assumes that the user doesn't have multiple secret keys. Therefore the hardware registration protocol limit number of distributed secret key to users to support the realization of the assumption.</p>\n<p dir=\"auto\">The cryptographic protocol which this idea used is named anonymous blocklisting protocol. The most popular anonymous blocklisting protocol is EPID(Enhanced Privacy ID). EPID is a signature scheme that ensures user anonymity but revocability. First, EPID realizes strong user privacy. In EPID, there is one public key and multiple private keys. So the verifier can't track users because the same public key is used to verify all signatures. Second, EPID has strong revocability. The servicer (i.e., verifier) can revoke the user(i.e., signer) with the user's signatures which were used for malicious actions. Note that the verifier doesn't need to track or identify users.</p>\n<p dir=\"auto\">Hardware registration protocol is for limiting the number of distributed secret keys to users. It assumes GM(i.e., Third Party for registration), and the user attests their device ID to GM and obtains the EPID secret key. Concretely, such attestation schemes are available, like TPM EK attestation, Android ID Attestation, or iOS DeivceCheck.</p>\n<h3 dir=\"auto\">References</h3>\n<p dir=\"auto\">EPID:</p>\n<ul dir=\"auto\">\n<li><a href=\"https://www.intel.com/content/www/us/en/developer/articles/technical/intel-enhanced-privacy-id-epid-security-technology.html\" rel=\"nofollow\">https://www.intel.com/content/www/us/en/developer/articles/technical/intel-enhanced-privacy-id-epid-security-technology.html</a></li>\n</ul>\n<p dir=\"auto\">TPM Attestation:</p>\n<ul dir=\"auto\">\n<li><a href=\"https://learn.microsoft.com/ja-jp/windows-server/identity/ad-ds/manage/component-updates/tpm-key-attestation\" rel=\"nofollow\">https://learn.microsoft.com/ja-jp/windows-server/identity/ad-ds/manage/component-updates/tpm-key-attestation</a></li>\n</ul>\n<p dir=\"auto\">Android ID Attestation</p>\n<ul dir=\"auto\">\n<li><a href=\"https://source.android.com/docs/security/keystore/attestation?hl=ja\" rel=\"nofollow\">https://source.android.com/docs/security/keystore/attestation?hl=ja</a></li>\n</ul>\n<p dir=\"auto\">DeivceCheck API</p>\n<ul dir=\"auto\">\n<li><a href=\"https://developer.apple.com/documentation/devicecheck\" rel=\"nofollow\">https://developer.apple.com/documentation/devicecheck</a></li>\n</ul>",
            "url": "https://github.com/antifraudcg/proposals/issues/19",
            "title": "Web hardware revocation API",
            "date_modified": "2023-10-11T19:36:23.000Z",
            "date_published": "2023-02-25T11:52:24.000Z",
            "author": {
                "name": "akakou",
                "url": "https://github.com/akakou"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/17723143?v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Hello! I'm from CAF, a Brazilian company founded in 2019 that aims to prevent identity fraud with a variety of products, such as digital onboarding, background checking and facial authentication.</p>\n<h2 dir=\"auto\">Context and threat</h2>\n<p dir=\"auto\">In successful attacks to steal legitimate accounts in LATAM, we observed several relevant signals that could be used for detection, however, one of the most relevant signals is the geolocation of the user/device.</p>\n<p dir=\"auto\">One of the most striking examples of recent years in Brazil is the physical theft of the device on streets of large cities like São Paulo or Rio de Janeiro.</p>\n<p dir=\"auto\">You can usually detect these events because:<br>\nA cell phone that has been stolen will likely be used in a different location than it was used in previous legitimate transactions;<br>\nSometimes, transactions also take place in areas considered risky by the company (anti-fraud company or company that owns the business);</p>\n<p dir=\"auto\">The same behavior can also be observed in cases of digital ATO, where criminals somehow manage to bypass the security controls implemented by the companies.</p>\n<h2 dir=\"auto\">Proposal</h2>\n<p dir=\"auto\">Our proposal is similar to the On-device Score Calculation proposal <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1390014856\" data-permission-text=\"Title is private\" data-url=\"https://github.com/antifraudcg/proposals/issues/16\" data-hovercard-type=\"issue\" data-hovercard-url=\"/antifraudcg/proposals/issues/16/hovercard\" href=\"https://github.com/antifraudcg/proposals/issues/16\">#16</a>, where the logic (Worklet) is pre-existing in a browser and the parameters are inserted remotely through a configuration API (called at the moment page/component load, for example).</p>\n<p dir=\"auto\">Combined with this API, there will also be another API capable of querying whether the location behavior pattern of that device (respecting the parameters configured initially), matches the desired one.</p>\n<p dir=\"auto\">For example:</p>\n<ol dir=\"auto\">\n<li>User visits a page of the money transfer feature (for example, using Brazil's instant transfer mechanism, known as PIX) - at this point a Worklet is configured with parameters from the anti-fraud company's backend - one of these parameters is the data of a polygon considered as a risk area by that company;</li>\n<li>At the time of the transaction, the browser, using logic/real and historical data from that user, concludes whether that device was present (geolocation) in that region initially configured or not in the last 24 hours (for example);</li>\n<li>The result of this On-device calculation must also be sent along with the request to the backend that will use it as a relevant signal for the decision to authorize or not this transfer transaction.</li>\n</ol>\n<p dir=\"auto\">The decision is entirely made On-device and can be configured in advance by the company interested in that signal.</p>\n<p dir=\"auto\">Seeking to protect the integrity of this device signal, it is also important to create some mechanism to prevent unwanted and malicious tampering with the device (anti-tampering).</p>\n<h2 dir=\"auto\">Relevant signals</h2>\n<ul dir=\"auto\">\n<li>Current location of user/device</li>\n<li>Location history</li>\n<li>Areas considered as high risk by that company</li>\n<li>Time of day</li>\n<li>Day of the week or month</li>\n</ul>\n<h2 dir=\"auto\">Privacy implications and safeguards</h2>\n<p dir=\"auto\">To avoid device position triangulation: add the need to provide a list of areas with minimum size.</p>\n<hr>\n<p dir=\"auto\">This post was made together with @ricardosw</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/18",
            "title": "Detect suspicious location behavior",
            "date_modified": "2022-10-28T17:42:32.000Z",
            "date_published": "2022-09-28T22:40:33.000Z",
            "author": {
                "name": "menegais1",
                "url": "https://github.com/menegais1"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/291287?u=688604471e42834a16b93856fa62709ccd44bf5c&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\"><em>(Disclaimer: this issue is intended to be a general discussion and is not a specific implementation proposal yet. It’s more an open conversation around the theme and approach then a defined proposal)</em></p>\n<p dir=\"auto\"><em>Identity fraud is a billion dollar problem in Brazil, generating compliance and regulatory rules that stop business operations from easily scaling up while maintaining security and User Experience. <strong>idwall's</strong> solutions use machine learning and other cutting edge solutions to provide our clients with answers to those problems in the best possible way.</em></p>\n<h1 dir=\"auto\">Context and threat</h1>\n<p dir=\"auto\">This threat is relevant to the <strong>Account Creation Abuse and Account Take Over (ATO) use-cases</strong>, a main one for any institutions concerned with <strong>fraud detection and containment in LATAM</strong>.</p>\n<p dir=\"auto\">Compromised devices are sophisticated attack vectors and can be used by well organized criminal groups as a weapon against legitimate businesses and users. Likewise, attack automation enables scale for an engaged malicious actor, pushing the need to prioritize its detection and containment for a better user experience.</p>\n<h1 dir=\"auto\">Proposal</h1>\n<p dir=\"auto\">Create a <strong>protocol to allow information exchange between devices (the mesh) preserving user privacy and, at the same time, identifying suspicious behavior in a distributed and resilient way</strong>.</p>\n<p dir=\"auto\">The proposal is to <strong>use the consensus between devices</strong> on genuine and suspect characteristics without transferring sensitive information associated with these decisions. The mesh network would only make available the device's behavior comparison result for a certain period of time, which could be used to determine the trust in the device current behavior.</p>\n<p dir=\"auto\">A device should be able to query from a safe and reliable source if another device has performed (within a defined period of time) some malicious action similar to the one it is going to perform, so it could make the decision not to perform that same action, autonomously.</p>\n<p dir=\"auto\">A <strong>malicious action can also be identified through anomaly detection</strong> when compared to behaviors considered genuine.</p>\n<p dir=\"auto\">This protocol can provide a consensus mechanism between devices (based on Yes/No questions - like Oracles - reducing the risk of leaking sensitive information), in order to create this “decentralized shared knowledge base” of actions that are being implemented and executed on specific domains.</p>\n<p dir=\"auto\"><strong>Entities such as Google and others could act as mediators between devices</strong> ensuring, through encryption and signatures (PKI), that the devices are able to create a network of trust with each other.</p>\n<h1 dir=\"auto\">Relevant signals</h1>\n<p dir=\"auto\">The signals will depend on the protocol to be created, however, it is possible to say that several signals that may indicate the compromise of a device can be used for this, such as \"If a device made many requests in the same domain in the last 60 minutes”.</p>\n<h1 dir=\"auto\">Privacy implications and safeguards</h1>\n<p dir=\"auto\">It is necessary to assume and mitigate that other mesh devices are unreliable and may actively seek to compromise the integrity of this feature.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/17",
            "title": "Device mesh (Androids/Chromes) to share suspicious behavior",
            "date_modified": "2022-11-07T19:48:36.000Z",
            "date_published": "2022-09-28T22:35:46.000Z",
            "author": {
                "name": "kazuoteramoto",
                "url": "https://github.com/kazuoteramoto"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/9621276?u=394abe57571581b8166afe95c3159e17623646a7&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Hey folks! I'm from CAF, a Brazilian company founded in 2019 that aims to prevent identity frauds with a variety of products, such as digital onboarding, background checking and facial authentication.</p>\n<h2 dir=\"auto\">Context and threat</h2>\n<p dir=\"auto\">Several types of attacks come from automation carried out by malicious agents engaged against legitimate targets and, in particular, against targets in the financial segment (web and mobile applications).</p>\n<p dir=\"auto\">The most relevant attacks monitored and contained by our team in LatAm refer to abuse in the creation of accounts in digital banks and fintech apps.</p>\n<p dir=\"auto\">In this context, creating fake accounts for money laundering or receiving stolen money in other ways has become quite important for cybercrime, especially in Brazil.</p>\n<p dir=\"auto\">Therefore, preventing account creation by malicious actors is important not only because of fraudulent account creation but it also prevents carrying out other scams, especially those related to phishing against legitimate users.</p>\n<p dir=\"auto\">Despite using real people data in their creation, these accounts are referenced as \"Orange accounts\" (straw-man, stooge accounts), as they are not controlled by the real owners, but by third parties, usually cybercriminals.</p>\n<p dir=\"auto\">An attack example that ends up using these accounts is what we know as the WhatsApp Scam, where a person impersonates another on WhatsApp and ends up managing to trick a legitimate user into making a fraudulent transfer to an \"orange\" account. The targets most exposed to this type of attack are older people who are unable to perform some type of validation during the conversation with the criminal.</p>\n<p dir=\"auto\">In most observed cases, abuse is not automated as digital banks already have several defenses in their KYC processes, but they are usually associated with high financial value transactions.</p>\n<p dir=\"auto\">In all transactions of this nature, we observe several similar characteristics (clear signs) of a fraud being carried out.</p>\n<h2 dir=\"auto\">Proposal</h2>\n<p dir=\"auto\">Our proposal is to create a device score mechanism respecting the regionalization/context where that transaction is taking place. Initially, this score would be just another signal for the decision to authorize or not a transaction, however, in a future version of this API, this decision could be made on-device.</p>\n<p dir=\"auto\">For example: Observing signs such as apps installed, apps cloned, battery level, number of times the user used the device in the last 24 hours, device usage pattern (eg if only one app was used many times in the same day, this could be a important signal) and various other signals, it is possible to assign a score for that device.</p>\n<p dir=\"auto\"><strong>To protect user privacy, our proposal is, similar to <a href=\"https://github.com/WICG/turtledove/blob/main/FLEDGE.md\">FLEDGE's</a> proposal</strong>, that a worklet, configured to load data(K,V)/endpoints from a legitimate backend (from an anti-fraud company, for example), could be used to make the decision (like an on-device auction) of the device score (in a first version, only pattern-matching rules could be used for the calculation – in the future, ML models could be loaded to a more complex calculation).</p>\n<p dir=\"auto\">In this proposal, instead of extracting data from the device, we load logic from reliable backends so that the score decision is kept on-device.</p>\n<p dir=\"auto\">Ideally, user consent should be requested for high-risk transactions that make use of this API, since a variety of data could be used in this calculation (all pre-existing client-side data).</p>\n<h2 dir=\"auto\">Relevant signs</h2>\n<p dir=\"auto\">Observing signs such as apps installed, apps cloned, battery Level, number of times the user used the device, device usage pattern (eg if only one app was used many times in the same day).</p>\n<h2 dir=\"auto\">Privacy implications and safeguards</h2>\n<p dir=\"auto\">If the implementation is carried out completely on-device, there is no exposure of end-user data for possible identification.</p>\n<hr>\n<p dir=\"auto\">This post was made together with <a class=\"user-mention notranslate\" data-hovercard-type=\"user\" data-hovercard-url=\"/users/menegais1/hovercard\" data-octo-click=\"hovercard-link-click\" data-octo-dimensions=\"link_type:self\" href=\"https://github.com/menegais1\">@menegais1</a>.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/16",
            "title": "Allow device score calculation based on context and without user exposure",
            "date_modified": "2022-10-28T17:38:30.000Z",
            "date_published": "2022-09-28T22:30:49.000Z",
            "author": {
                "name": "ricardogarim",
                "url": "https://github.com/ricardogarim"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/114111307?v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We are <strong>Allowme</strong>, a business unit from Tempest Security Intelligence, a cybersecurity company from Brazil, Latam, with more than 22 years in operation. Allowme's mission is to help companies protect the digital identities of their legitimate customers through a complete fraud prevention platform.</p>\n<p dir=\"auto\"><strong>Context and threat</strong><br>\nAutomation is one of the main requirements for large scale attacks and high profit for attackers, therefore, it has become a priority from a malicious actor's point of view.</p>\n<p dir=\"auto\">When doing a massive attack, fraudsters usually use navigation automation tools without a graphical interface, or Headless Browser (<a href=\"https://en.wikipedia.org/wiki/Headless_browser\" rel=\"nofollow\">https://en.wikipedia.org/wiki/Headless_browser</a>), usually using versions of Chrome Webdriver (https ://en.wikipedia.org/wiki/Selenium_(software)#Selenium_WebDriver).</p>\n<p dir=\"auto\">However, a common characteristic in attacks of this nature is that the attacker essentially needs to create many instances of browsers to execute the attack and, when this is done, in general the created browser has very unique characteristics, as if they were installations performed at that moment.</p>\n<p dir=\"auto\"><strong>Proposal</strong><br>\nBeing able to accurately and safely attest to improper manipulations, the lifetime of that User Agent instance, from its initialization to the present moment, can be of extreme importance and value in the detection of automated threats, both on the web and on mobile devices.</p>\n<p dir=\"auto\">On web browsers<br>\nThe combination of different signals could be used to estimate the lifetime of a device running, for example: lifetime of cookies, time of plugin installation, time since last update, lifetime of an associated profile to the browser, etc.</p>\n<p dir=\"auto\">On mobile devices<br>\nFor mobile devices, knowing the OS lifetime can be even more accurate, as the hardware can indicate this, in addition to the connection between the device and the manufacturer's application store (Google Play or Apple Store).</p>\n<p dir=\"auto\">On Android, for example, we could use some relevant information, such as:<br>\nDate of acquisition of an App on Google Play<br>\nDate of installation/re-installation of the App on Google Play</p>\n<p dir=\"auto\">However, an important decision to be made is whether to recompile Apps after the first installation, as this could compromise the lifetime of a given App.</p>\n<p dir=\"auto\"><strong>Privacy implications and safeguards</strong><br>\nThere is no PII data being used to calculate the lifetime of a particular device, so there is very little threat to user privacy.</p>\n<p dir=\"auto\">However, this data could be used as an additional signal to re-identify users if combined with browsing history and other behavioral information.</p>\n<p dir=\"auto\"><strong>Safeguard <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1124054184\" data-permission-text=\"Title is private\" data-url=\"https://github.com/antifraudcg/proposals/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/antifraudcg/proposals/issues/1/hovercard\" href=\"https://github.com/antifraudcg/proposals/issues/1\">#1</a></strong><br>\nThe API could only return if the lifetime is longer than a specific time period, for example:<br>\nIf the lifetime is longer than 1 day<br>\nIf the lifetime is longer than 1 week<br>\nIf the lifetime is more than 1 month<br>\nIf the lifetime is more than 3 months<br>\nIf the lifetime is more than 1 year</p>\n<p dir=\"auto\">Thus, it would be difficult to use this data to identify a person, even when combined with other user behavior data.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/15",
            "title": "Attestation of device lifetime",
            "date_modified": "2024-07-19T06:41:39.000Z",
            "date_published": "2022-09-21T20:48:34.000Z",
            "author": {
                "name": "pamellaprevedel-hpm",
                "url": "https://github.com/pamellaprevedel-hpm"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/85939526?u=a77ed98e182e1835c1b4bc3aec631c8bf0e35551&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We are <strong>Allowme</strong>, a business unit of Tempest Security Intelligence, a cybersecurity company from Brazil, Latam, with more than 22 years in operation. Allowme's mission is to help companies protect the digital identities of their legitimate customers through a complete fraud prevention platform.</p>\n<p dir=\"auto\"><strong>Context and threat</strong><br>\nIn the context of fraud in web applications, seeking financial gain depends, almost entirely, on the possibility of automating tactics. Based on this assumption, being able to re-identify an attacker is essential to remove the scale of an attacker. For this detection to be possible, an attacking device detected in a context should be easily identified during a new attack, targeted towards something new, or towards the same previous target.</p>\n<p dir=\"auto\"><strong>Proposal</strong><br>\nSomehow, persistently storing (non-manipulating) information on the device (4 bits) is essential to ensure more effective (efficient and effective) defenses and controls, while maximizing the user experience for legitimate users.</p>\n<p dir=\"auto\">This signal will not be the only one used for fraud identification, however it may be relevant for a fraud application when this signal is marked true on a specific device.</p>\n<p dir=\"auto\">This functionality can be implemented in both Web browsers (eg Chrome) and mobile operating systems (eg Android).</p>\n<p dir=\"auto\">A similar implementation would be Apple's DeviceCheck, available at: <a href=\"https://developer.apple.com/documentation/devicecheck\" rel=\"nofollow\">https://developer.apple.com/documentation/devicecheck</a></p>\n<p dir=\"auto\"><strong>Relevant signals</strong><br>\nSecure and persistent storage area on the device<br>\nBrowser lifetime</p>\n<p dir=\"auto\"><strong>Privacy implications and safeguards</strong><br>\nSince this information does not reveal any user PII and is only relevant to fraud detection and containment systems, there is no threat to user privacy.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/14",
            "title": "Mark device as a fraudster - eg DeviceCheck",
            "date_modified": "2022-10-28T17:34:19.000Z",
            "date_published": "2022-09-21T18:13:57.000Z",
            "author": {
                "name": "Guar1s",
                "url": "https://github.com/Guar1s"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/85939526?u=a77ed98e182e1835c1b4bc3aec631c8bf0e35551&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We are <strong>Allowme</strong>, a business unit of Tempest Security Intelligence,  a cybersecurity company from Brazil, Latam, with more than 22 years in operation. Allowme's mission is to help companies protect the digital identities of their legitimate customers through a complete fraud prevention platform.</p>\n<p dir=\"auto\">Through our Security by Design culture, AllowMe has become the most trusted platform on the market, protecting valuable data and the reputation of innovative businesses.</p>\n<p dir=\"auto\">We facilitate faster and more accurate decision making, optimizing flows to scale business sustainably.</p>\n<p dir=\"auto\"><strong>Threat Context</strong><br>\nThe use of security mechanisms is needed for digital identities attestation and protection. To achieve that, many authentication factors are used, including biometric facial authentication, which is becoming more common.</p>\n<p dir=\"auto\">One of the main attack paths, which compromise facial validation, is the use of external mechanisms to inject 3rd party photos and videos impersonating someone else, known as face spoofing attacks (instead of using the native camera).</p>\n<p dir=\"auto\">An engaged attacker could easily collect the target's social media photos and use them to open accounts on digital banks on behalf of these targets in LATAM, without consent or authorization of the owners. During Know Your Client (KYC) processes for financial services, many documents are usually requested, making document pictures upload a mandatory feature, which became possible pathways for Identity Falsification Attacks or Fake Accounts Creation.</p>\n<p dir=\"auto\"><strong>Proposal</strong><br>\nTo have a safe and reliable way to know if the photo of the face or of a physical document was taken from a physical native camera (or not). In other words, the proposal is to have a way to attest the underlying method to collect that data (picture) to avoid spoofing.</p>\n<p dir=\"auto\"><strong>Privacy implications and safeguards</strong><br>\nThere are no PII being used for origin identification of the picture.</p>\n<p dir=\"auto\"><strong>Safeguard <a class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1124054184\" data-permission-text=\"Title is private\" data-url=\"https://github.com/antifraudcg/proposals/issues/1\" data-hovercard-type=\"issue\" data-hovercard-url=\"/antifraudcg/proposals/issues/1/hovercard\" href=\"https://github.com/antifraudcg/proposals/issues/1\">#1</a></strong><br>\nThe API could return only a bit informing if the image has been captured through the native physical hardware or not.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/13",
            "title": "Camera integrity certification for facial biometrics and physical documents attestation",
            "date_modified": "2022-10-28T17:31:36.000Z",
            "date_published": "2022-09-16T19:10:35.000Z",
            "author": {
                "name": "Guar1s",
                "url": "https://github.com/Guar1s"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/61555125?u=28d79fc217078bd0db885acd12b544f56aafa32c&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Domain Spoofing (aka Domain Laundering) is a form of Sophisticated Invalid Traffic (SIVT) in which a false representation is made about the domain associated with an ad impression. Two examples are when the domain in the ad request is different from the domain of the actual inventory being supplied or the actual ad is rendered to a different website or application than the one identified in the ad request. (See “False Representation” on page 8 of the Trustworthy Accountability Group (TAG) <a href=\"https://f.hubspotusercontent40.net/hubfs/2848641/Invalid%20Traffic%20Taxonomy%20(IVT)/IVT%20Taxonomy%20v2.0.pdf\" rel=\"nofollow\">TAG Invalid Traffic Taxonomy v2.0</a>.)</p>\n<p dir=\"auto\">Four commonly identified expressions of Domain Spoofing are:</p>\n<ul dir=\"auto\">\n<li>URL Substitution\n<ul dir=\"auto\">\n<li>Simple replacement of the URL in an ad/bid request.</li>\n</ul>\n</li>\n<li>Cross-domain Embedding\n<ul dir=\"auto\">\n<li>Using frames to embed a high-quality domain within a page on a low-quality domain or simply to hide the top-level domain in the ad or bid request.</li>\n</ul>\n</li>\n<li>Custom Browsers\n<ul dir=\"auto\">\n<li>Using a custom browser which provides falsified URL and host information.</li>\n</ul>\n</li>\n<li>Malware\n<ul dir=\"auto\">\n<li>Hijacks pages and Injects ad tags into otherwise legitimate pages.</li>\n</ul>\n</li>\n</ul>\n<p dir=\"auto\">Of these, the latter two seem to be out of scope: the third, custom browsers, obviously aren’t subject to W3C standards; the forth, malware, would be unreasonably difficult for browsers to defend against and is better dealt with via mechanisms like ads.txt and ads.cert validations on the parts of SSPs, DSPs and/or ad-verification vendors.</p>\n<p dir=\"auto\">For the first two, a simple, straightforward and effective countermeasure would be for browsers to include a header value containing the eTLD+1 of the page in every request. Inclusion of the value could be made optional, with site owners having the ability to tell the browser not to provide it in cases where it is considered to be sensitive or otherwise inappropriate.</p>\n<p dir=\"auto\">If each browser request included the eTLD+1 in a header, all the key constituencies in the ad supply chain which interact with the browser would have an opportunity to validate the impressions they’re buying, or have purchased, are from the top-level page the user sees in their address bar.</p>\n<p dir=\"auto\">There is some server-to-server communication that happens between entities, like SSPs and DSPs, which allow for manipulation of bid requests, so the method isn’t entirely preemptive. However, because buyers subsequently interact with the browser directly via creatives, various measurement pixels and other interactions, were an intermediary to misrepresent the source of an impression, it could be easily caught, the source black-listed and payment withheld.</p>\n<p dir=\"auto\">Providing the eTLD+1 of the page would be particularly valuable in cases where impressions are isolated from the host page by nested iFrames, as is common when publishers work with resellers.</p>\n<p dir=\"auto\">Although the focus here is on ad-tech, given the central role eTLD+1 plays in the web, it seems likely making eTLD+1 generally available will support other antifraud use-cases as well.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/12",
            "title": "Add eTLD+1 Request Header to Expose Domain Spoofing",
            "date_modified": "2022-10-28T17:27:33.000Z",
            "date_published": "2022-06-10T19:07:32.000Z",
            "author": {
                "name": "bmayd",
                "url": "https://github.com/bmayd"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/10235?v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We would like to propose a new API for the browser to reveal a <a href=\"https://en.m.wikipedia.org/wiki/Data_binning\" rel=\"nofollow\">bucketized</a> time interval since any cookies for the inquiring origin were reset. The goal of the API is to provide a low entropy signal that can be useful for identifying deceptive clients that reset their partitioned state in order to appear as a multitude of distinct clients.</p>\n<p dir=\"auto\">The ability to differentiate between unique users and overactive clients is paramount for fighting <a href=\"https://antifraudcg.github.io/charter.html\" rel=\"nofollow\">online fraud and abuse</a>, such as DoS attacks and invalid traffic. Third-party cookies currently provide anti-abuse systems with a simple way of uniquely identifying users across the web. For example, this ability allows us to determine if there is unusual activity (multiple requests or clicks) associated with a single cookie which could be interpreted as abuse.</p>\n<p dir=\"auto\">Given the ease that third-party cookies provide for distinguishing unique user activity, it is natural for bad actors to avoid detection by clearing their cookies. Alternatively, they can use multiple bots to perform the same type of abuse. In doing so however, bad actors allow service providers to detect abuse using a different signal: the cookie age. Indeed, to successfully conduct a large-scale attack, the cookie age observed on the traffic generated by an abuser will tend to follow a very different pattern than that of regular traffic, thereby allowing abuse detection organizations to cluster abnormal behavior using this signal.</p>\n<p dir=\"auto\">With the forthcoming <a href=\"https://blog.google/products/chrome/updated-timeline-privacy-sandbox-milestones/\" rel=\"nofollow\">deprecation of third-party cookies</a>, abuse detection organizations will lose the ability to uniquely identify users and to analyze clusters of cookie age. One possible solution to recover the cookie age signal is the use of the <a href=\"https://web.dev/trust-tokens/\" rel=\"nofollow\">Trust Token API</a>, which allows issuers to encode a cross site signal of ~2.58 bits. The main limitation of this technology is that browsers must impose a <a href=\"https://github.com/WICG/trust-token-api#mitigation-per-site-issuer-limits\">limit</a> on the number of tokens that can be redeemed on a website. This is due to the fact that each token contains ~2.58 bits of information, so the use of multiple tokens could be used as a cross-site fingerprint.</p>\n<p dir=\"auto\">Given the considerations and constraints discussed above, we believe that age signals will allow partitioned cookies to be a crucial component for future abuse detection systems. This document proposes for Chrome to provide a CookieAge API that would encode the time since a user reset any cookies associated with the inquiring origin. The CookieAge API would return a low entropy representation of the age of relevant cookies. This could for instance be a bucketized age in N buckets, where N would be small enough to ensure that the signal cannot be used as a fingerprint.</p>\n<p dir=\"auto\"><strong>What properties should the partitioned cookie age age have?</strong></p>\n<ul dir=\"auto\">\n<li>The cookie age should be resettable</li>\n<li>The cookie age should be “young” when a browser just started</li>\n<li>The cookie age should not allow an observer to detect whether the user is in Incognito mode or not.</li>\n</ul>\n<p dir=\"auto\">Based on the above considerations, we think the cookie age should encode the time since a browser set its first cookie associated with the inquiring origin, and should reset to zero whenever any cookie associated with the inquiring origin is reset.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/9",
            "title": "Cross-Partition Cookie Age Signal for Abuse Detection",
            "date_modified": "2022-10-28T17:20:25.000Z",
            "date_published": "2022-05-02T19:12:53.000Z",
            "author": {
                "name": "philippp",
                "url": "https://github.com/philippp"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/10235?v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Chrome proposes developing a high-level document to capture use-cases and requirements for device attestation and other high-fidelity, low-entropy signals. This is a call for collaboration among interested members of the anti-fraud community group to identify important signals for Invalid Traffic (IVT) detection and other relevant security use cases.</p>\n<p dir=\"auto\">Many modern platforms have built-in tools to help differentiate legitimate and emulated devices. Android provides applications with the <a href=\"https://developer.android.com/training/safetynet\" rel=\"nofollow\">Safety Net API</a> and Apple’s App Attest offers some of the same protections.<br>\nBy transmitting signals of legitimacy from the device’s platform, such as if the device is emulated or rooted, publishers and their technology partners could use this information in part to determine if traffic is invalid. They could then choose appropriate actions like flagging advertising actions as suspicious or requiring more information for sensitive actions like logins or financial transactions. These signals could be open for all websites to consume and could additionally facilitate a variety of other security use cases in a privacy compliant manner.</p>\n<p dir=\"auto\">We would like to forward the most useful integrity signals on each platform, and provide a unified representation to web sites and applications.</p>\n<p dir=\"auto\">There are many open questions in this area that we’d like to explore:</p>\n<ol dir=\"auto\">\n<li>Would a platform signal attesting to the device’s legitimacy be a useful addition?</li>\n<li>What integrity signals would be most useful? (For example, device booted from manufacturer-signed firmware, browser runtime integrity checks, etc.)</li>\n<li>Would an ideal implementation reduce (not eliminate) the need for fingerprinting?</li>\n<li>What remaining needs would require fingerprinting (for example, enforcing uniqueness / sign-up protections; cookie theft prevention)?</li>\n<li>What other signals are derived from common fingerprinting surfaces that browsers could surface in a privacy safe manner?  For - example, geo, time since last state clear, etc.?</li>\n<li>What about longitudinal signals?  Should the browser play a role here at all?</li>\n<li>How do we experiment with new signals or a changing threat landscape?</li>\n<li>What would be useful on platforms that do not have a comprehensive attestation framework?</li>\n</ol>\n<p dir=\"auto\">Potential challenges</p>\n<ol dir=\"auto\">\n<li>How do we maintain equitable access to the web for users with older devices or platforms, which may not provide this signal?</li>\n<li>Should we introduce some noise, or hold back the signal on some fraction of devices to prevent over-reliance on these signals</li>\n<li>Will threat actors shift to using valid devices that provide these signals, and will the additional cost of attacks cause only temporarily reduce fraud? How soon might these signals become stale over time?</li>\n</ol>\n<p dir=\"auto\">We’d like to start an effort to explore this approach, starting with requirements gathering, in the Anti-Fraud Community Group, and would welcome collaboration.</p>\n<p dir=\"auto\">Related work:</p>\n<ul dir=\"auto\">\n<li><a href=\"https://github.com/w3c/webpayments/wiki/UserConfidenceScore\">User Confidence Score</a></li>\n<li><a href=\"https://github.com/WICG/trust-token-api#non-web-sources-of-tokens\">Trust Tokens API</a></li>\n</ul>",
            "url": "https://github.com/antifraudcg/proposals/issues/8",
            "title": "Device Integrity Attestation through the Browser",
            "date_modified": "2023-11-10T05:20:58.000Z",
            "date_published": "2022-04-13T22:28:52.000Z",
            "author": {
                "name": "philippp",
                "url": "https://github.com/philippp"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/545707?u=a1beaaa150ae1eb88a138fa3e02f5e58879a80cf&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Following up from the presentation today, I'd like to eventually propose moving the Trust Token API work from the WICG to the Anti-Fraud CG.</p>\n<p dir=\"auto\">Current Documents: <a href=\"https://github.com/WICG/trust-token-api/\">https://github.com/WICG/trust-token-api/</a></p>\n<p dir=\"auto\">I'm opening this issue for early feedback about moving the API, prior to sending out a call to adopt the work on the list.</p>\n<p dir=\"auto\">Please provide feedback/thoughts on this issue or via the Slack.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/7",
            "title": "Private State Tokens",
            "date_modified": "2024-02-01T17:24:38.000Z",
            "date_published": "2022-04-01T17:08:54.000Z",
            "author": {
                "name": "dvorak42",
                "url": "https://github.com/dvorak42"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/99846904?v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\"><strong>Balancing Privacy and Security with an Anti-Fraud Safelist</strong></p>\n<p dir=\"auto\"><strong>Background</strong></p>\n<p dir=\"auto\">Today’s fraud controls are a societal good and a necessary part of our global economy. At the same time, internet users have a right to privacy, and thus deserve consent-driven tools that prevent abusive or unwanted tracking on the Internet.</p>\n<p dir=\"auto\">The goal of this proposal is to provide a consent-driven framework through which fraud-detection stakeholders may continue to capture signals that have great value during identity verification and authentication. The proposal stems from a concern that other privacy-centric proposals under consideration by the W3C will have a substantial negative impact on controls that keep consumers, organizations &amp; governments safe from fraud.</p>\n<p dir=\"auto\"><strong>Specific Concerns Regarding Proposed Privacy Measures</strong></p>\n<p dir=\"auto\">Google’s Privacy Sandbox represents some of the most prominent recent proposals concerning browser privacy. Collectively, these proposals would have a great impact on existing fraud controls. For example, were proposals concerning device entropy and IP masking to be implemented in some fashion, we expect to see the following degradation in fraud controls:</p>\n<ul dir=\"auto\">\n<li>Limited ability to profile and stop fraud rings during organized attacks</li>\n<li>Inability to identify IP concealment schemes, such as TOR, proxy servers, or malicious VPN activity</li>\n<li>Limited ability to identify foreign actors or criminal networks</li>\n<li>Elimination of signals used to identify bots or traffic from hosting facilities</li>\n<li>Reduced capabilities around anomaly detection during verification and authentication</li>\n<li>Limited capabilities around re-identification of customer devices for risk based authentication</li>\n<li>Greatly reduced utility of IP geolocation as a signal in fraud prevention</li>\n</ul>\n<p dir=\"auto\">We believe that it is essential that these new proposals be implemented with additional measures to ensure that fraud controls remain effective.</p>\n<p dir=\"auto\"><strong>Proposal - Anti-Fraud Safelist</strong></p>\n<p dir=\"auto\">We are in favor of carve-outs or exemptions to certain browser privacy controls for companies and organizations with a focus on fraud-detection or account security. Criteria for certification are discussed later in this document.</p>\n<p dir=\"auto\">We propose that browsers maintain safelists consisting of certified parties who meet rigorous ethical standards. Browser and IP data would be visible to certified parties, but only in high-risk contexts. Users would then have the ability to add or remove organizations from the safelist via settings in their browsers.</p>\n<p dir=\"auto\">These high-risk contexts would be identified in HTML markup, and the specific fraud-detection organization would be tagged accordingly in order to enable a handshake between the browser and their services.</p>\n<p dir=\"auto\">This approach would enable high-trust interactions, but only in risky contexts where a user is identifying themselves to a service provider. The approach would respect consent and protect against ubiquitous surveillance mechanisms.</p>\n<p dir=\"auto\"><strong>HTML Markup for High Risk Contexts</strong></p>\n<p dir=\"auto\">In order to honor the intent of browser privacy proposals, we advocate that device and IP details only be revealed to 3rd parties in limited high risk contexts. High risk contexts represent a small minority of day-to-day interactions on the internet and include situations where a user is:</p>\n<ul dir=\"auto\">\n<li>Identifying themselves for the first time, in order to become a user of a platform or service</li>\n<li>Initiating a monetary transaction, for example, a funds transfer or eCommerce checkout</li>\n<li>Authenticating themselves at the start of a session or during step-up authentication</li>\n<li>Changing or updating account information, for example, initiating a password-reset or update to a mailing address or phone number</li>\n<li>Adding another user to an account, for example a secondary user of a credit card</li>\n<li>Claiming benefits from a government</li>\n</ul>\n<p dir=\"auto\">For such a scheme to work, site owners would need a mechanism to declare that a particular page or interaction is high risk. Such a declaration would ideally include:</p>\n<ul dir=\"auto\">\n<li>A declaration of purpose (e.g. ‘Auth’, ‘Verify’, ‘Transact’)</li>\n<li>A certified authority (e.g. anti-fraud solution provider) that is present on the safelist</li>\n<li>A scope in which data collection could occur. For example:<br>\n-- A URL corresponding to an endpoint managed by the authority<br>\n-- An iFrame on the authority’s domain</li>\n</ul>\n<p dir=\"auto\">The markup itself could take many forms, from a new type of tag to a declaration within a meta tag. This initial proposal does not cover the semantics of such markup.</p>\n<p dir=\"auto\">Organizations employing device-centric fraud controls typically have three options for integration with a web site:</p>\n<ol dir=\"auto\">\n<li>Client side javascript libraries</li>\n<li>Server side inspection via a pixel or similar interaction prompted by a GET request</li>\n<li>Implementation of a reverse proxy, potentially in conjunction with 1 and 2</li>\n</ol>\n<p dir=\"auto\">This proposal as articulated would serve options 1 and 2, but not 3. This is intentional as a reverse proxy managed by a 3rd party service is omnipresent during web sessions and not observable by an end user. As such, scope for data collection would be ambiguous, or worse, universal within a session. That said, there is no reason why an organization employing a reverse proxy couldn’t use it in conjunction with options 1 and 2, meaning that they would still be in a position to collect relevant device and IP details, but only in high risk contexts.</p>\n<p dir=\"auto\"><strong>Certification Process for Fraud Detection Organizations</strong></p>\n<p dir=\"auto\">As it stands, most browsers ship with built in SSL certificates corresponding to <a href=\"https://wiki.mozilla.org/CA/Application_Process\" rel=\"nofollow\">verified Certificate Authorities</a>. We propose that a similar practice be implemented in relation to the fraud detection safelist. Browser manufacturers would define their own process for diligence, which presumably would require participant organizations to complete annual audits and sign corresponding affidavits.</p>\n<p dir=\"auto\">While a public standard for such audits is out of scope for this document, we propose the following criteria for certification:</p>\n<ol dir=\"auto\">\n<li>The candidate organization should exclusively be involved in Fraud Detection or Account Security (this is to avoid conflicts of interest with Martech/Adtech)</li>\n<li>Collected data is exclusively used for Fraud Detection or Account Security.</li>\n<li>Organization meets rigorous ethical standards [TBD]</li>\n<li>Organization meets rigorous standards for data security [TBD]</li>\n<li>Organizations are prohibited from selling data collected in these contexts to outside parties</li>\n</ol>\n<p dir=\"auto\">As further context, it is worth considering that a number of large organizations are simultaneously active in Advertising and Fraud Detection, and utilize the same underlying device observations across their various solutions. This type of behavior is antithetical to the intent of this proposal, which assumes that user consent and preferences are directed toward security and fraud controls. The above criteria are intended to prohibit those sorts of activities, as well as large scale surveillance operations.</p>\n<p dir=\"auto\">In future phases, companies that do not have an exclusive focus on fraud detection &amp; account security may participate in the program. This will require enforcement of further standards governing the complete separation of data and systems from processes that do not exclusively support fraud prevention &amp; identity assurance.</p>\n<p dir=\"auto\">Should this proposal move forward, we hope that a neutral organization with a history of drafting standards for certification would set the baseline for the review process in the form of a public standard. Such a standard could be authored by W3C members, or another credible organization like the FIDO Alliance or The Kantara Initiative.</p>\n<p dir=\"auto\"><strong>Additional Anti-Abuse Measures</strong></p>\n<p dir=\"auto\">While the certification process outlined in this proposal is intended to ensure that bad-actors do not participate in the anti-fraud safelist, there is still the potential for a certified party to overstep the intent of this scheme by labeling large portions of a website as ‘high risk’, and thus enabling unwanted data collection on a broad basis. This could be further exacerbated if such a scheme was implemented across multiple web properties in order to enable large scale tracking.</p>\n<p dir=\"auto\">While we don’t prescribe a particular approach to tackle this problem, we do envision that browsers could implement further anti-abuse measures to stem these concerns, including:</p>\n<ul dir=\"auto\">\n<li>Contextual analysis of web pages and traffic patterns to understand if user interactions and DOM elements are typical of sign up or authentication flows, or if the majority of the web property is oriented towards a high risk service (e.g. payments platforms or federated authentication)</li>\n<li>Analysis of  anonymized web traffic in order to identify the proportion of a given web property that is tagged as ‘high risk’</li>\n<li>Analysis of cross domain web traffic to identify collusion between anti-fraud organizations and other parties, for example adtech platforms</li>\n</ul>\n<p dir=\"auto\"><strong>Implications for Users if No Exceptions Exist for Fraud Controls</strong></p>\n<p dir=\"auto\">If institutions are not able to verify the identities of applicants in high-risk circumstances, this will lead to a number of negative consequences for consumers. Generally, more data will be gathered. By trying to avoid less invasive profiling, users end up having to provide even more information.</p>\n<p dir=\"auto\">The following are some examples of challenges that users face when passive fraud controls fail to verify an identity:</p>\n<ul dir=\"auto\">\n<li>Automated collection of documentation and biometrics (e.g. driver’s license + selfie + liveness)</li>\n<li>Collection of corroborating evidence of an identity (e.g. utility bills, proof of residence, SSN card, SSA 89 form)</li>\n<li>Phone calls to the applicant <em>or the family of the applicant</em> asking if the applicant actually initiated a given interaction [a somewhat common practice amongst card issuers]</li>\n<li>In-person authentication</li>\n<li>A requirement to see an in-person notary</li>\n<li>A requirement to go to a branch office and show (often) 2 forms of ID</li>\n<li>Online notary, which would require both document verification, forms, interview &amp; attestation</li>\n</ul>\n<p dir=\"auto\"><strong>User Consent Models</strong></p>\n<p dir=\"auto\">We propose that user consent options follow the following design pattern:</p>\n<p dir=\"auto\">Browsers display a visual notification when a user encounters a high risk context. The UI prompt should enable the user to see verbose details about the context (perhaps on hover). Details would include:</p>\n<ul dir=\"auto\">\n<li>A link to information describing the particular types of data that may be collected</li>\n<li>A declaration of purpose for the data collection (e.g. ‘Authentication’, ‘ID Verification’, ‘Transaction Security’)</li>\n<li>The name of the organization that is collecting the information and a link to more details about their operations and mission</li>\n<li>A link to consent preferences, where users can add or remove organizations from the safelist, or opt into an ad hoc consent process</li>\n</ul>\n<p dir=\"auto\">Users who have opted into ad-hoc consent will be prompted to approve or deny requests for added information on a case by case basis</p>\n<p dir=\"auto\">By default, users are opted into a safelist according to the default preferences that ship with their browser. We prefer this model to universal capture of ad hoc consent, which we fear would disincentivize participation, which would in turn push users into more invasive workflows.</p>\n<p dir=\"auto\">As an added note, we have spoken to security professionals who are of the opinion that consent options will undermine fraud use cases as criminals will opt out, as will privacy-minded consumers. It is easy to imagine an alternate form of this proposal where the safelist is not configurable by users, and certainly that approach has some advantages in terms of security for organizations on the web.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/4",
            "title": "Anti-Fraud Safelist",
            "date_modified": "2022-10-28T17:12:06.000Z",
            "date_published": "2022-02-17T00:01:07.000Z",
            "author": {
                "name": "samuel-t-jackson",
                "url": "https://github.com/samuel-t-jackson"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/73904805?u=0872d610f7fb7b77aa8b8274d8bd622ed28ca6f3&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We propose developing a high-level document to capture use-cases and requirements for trustworthy anti-fraud servers. This is a call for collaboration among interested members of the community group.</p>\n<p dir=\"auto\">Fraud detection and enforcement is one common use case that relies on third-party cookies and sensitive user data.  <a href=\"https://github.com/w3c/web-advertising/blob/main/support_for_advertising_use_cases.md#fraud-prevention\">There are more details about the need for this functionality in advertising use cases here.</a>  As browsers proceed to remove support for third-party cookies, this is an important use case that needs to continue to be supported.</p>\n<p dir=\"auto\">One avenue to support this use case is the use of trustworthy servers to process relevant data. There are existing technical proposals that allow sensitive user data to be safely sent from the browser to a server, provided that there are guarantees for what the server does with the data (this is what makes it trustworthy).  An example of this is the <a href=\"https://github.com/WICG/conversion-measurement-api/blob/main/SERVICE.md\">Aggregate Reporting Service</a> that uses cross-site user data. Note that non-technical guarantees, such as auditing, are out of scope for this proposal at the moment.</p>\n<p dir=\"auto\">We would like to use this discussion to then propose developing a similar scheme where the browser would send a minimum set of signals necessary for running ad fraud detection algorithms to one or more servers that could determine whether this is fraudulent traffic or not.  One assumption we’re making here is that the algorithms are compute-heavy and therefore too costly to run in the browser itself (e.g. Machine Learning model evaluation) - we’d like to validate that first and determine whether it introduces a DoS risk.  Another assumption is that attackers control the browser and so moving processing out of that environment may be beneficial.</p>\n<p dir=\"auto\">There are many open questions in this area that we’d like to explore:</p>\n<ol dir=\"auto\">\n<li>What signals are necessary to get various quality results?</li>\n<li>What do ad fraud detection algorithms require to run beyond their input data?  For example:\n<ul dir=\"auto\">\n<li>Are the algorithms proprietary and/or open source? Can these algorithms be publicly shared without compromising them or exposing their developers to reverse engineering risks?</li>\n<li>How complex are the calculations that they perform?</li>\n</ul>\n</li>\n<li>What sorts of technical protections best match the requirements above?\n<ul dir=\"auto\">\n<li>There are various useful things in this area: Secure Multi-Party Computation, Fully Homomorphic Encryption, Trusted Execution Environments, etc.</li>\n</ul>\n</li>\n<li>Approximate ad fraud decisions can be made with a minimal set of signals, but how do we fine-tune what signals go into that set?  Put another way: how do we experiment with new signals?\n<ul dir=\"auto\">\n<li>In practice, novel attacks can be entirely undetected if they are not covered by current signals and methods. Can system operators examine raw signals in some constrained setting in order to understand attacks?</li>\n</ul>\n</li>\n<li>Who would own and operate the servers?</li>\n</ol>\n<p dir=\"auto\">We’d like to start an effort to explore this approach, starting with requirements gathering, in the Anti-Fraud Community Group, and would welcome collaboration.</p>\n<p dir=\"auto\">Related work:</p>\n<ul dir=\"auto\">\n<li><a href=\"https://developer.chrome.com/docs/privacy-sandbox/trust-tokens/\" rel=\"nofollow\">Trust Tokens API</a></li>\n<li><a href=\"https://github.com/google/ads-privacy/tree/master/proposals/astrapia\">ASTRAPIA proposal</a></li>\n</ul>",
            "url": "https://github.com/antifraudcg/proposals/issues/3",
            "title": "Fraud prevention trusted server",
            "date_modified": "2022-10-28T17:09:40.000Z",
            "date_published": "2022-02-10T15:35:28.000Z",
            "author": {
                "name": "p-j-l",
                "url": "https://github.com/p-j-l"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/5284154?u=f69fa08bf0437084ba78f885224286c06851652d&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">We should remove \"Performed by owners of websites displaying ads, competitors and vandals.\" from <a href=\"https://github.com/antifraudcg/proposals/blob/main/use-cases/use-cases.md#invalid-traffic-ivt\">https://github.com/antifraudcg/proposals/blob/main/use-cases/use-cases.md#invalid-traffic-ivt</a>. It could also be performed by, for example, users who are getting some kind of reward for viewing ads. I think \"Invalid traffic is any activity that doesn't come from a real user with genuine interest.\" is sufficient.</p>",
            "url": "https://github.com/antifraudcg/proposals/issues/2",
            "title": "Remove scoping down of invalid traffic actors",
            "date_modified": "2022-02-18T17:57:15.000Z",
            "date_published": "2022-02-04T17:20:01.000Z",
            "author": {
                "name": "ShivanKaul",
                "url": "https://github.com/ShivanKaul"
            }
        },
        {
            "content_html": "<img src=\"https://avatars.githubusercontent.com/u/456061?u=d59b65c830ae2c442ea1dec8782dbfe7717f551f&v=4\" width=\"64\" height=\"64\" alt=\"\"/><br/><p dir=\"auto\">Initial draft: <a href=\"https://github.com/antifraudcg/proposals/blob/main/use-cases/use-cases.md\">https://github.com/antifraudcg/proposals/blob/main/use-cases/use-cases.md</a></p>",
            "url": "https://github.com/antifraudcg/proposals/issues/1",
            "title": "Proposal for use cases and threat models",
            "date_modified": "2022-10-25T14:07:12.000Z",
            "date_published": "2022-02-04T10:41:53.000Z",
            "author": {
                "name": "dtheodorakis",
                "url": "https://github.com/dtheodorakis"
            }
        }
    ]
}